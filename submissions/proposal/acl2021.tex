%
% File acl2021.tex
%
%% Based on the style files for EMNLP 2020, which were
%% Based on the style files for ACL 2020, which were
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2021}
\usepackage{times}
\usepackage{latexsym}
\usepackage{usebib}
\bibinput{acl2021}
\renewcommand{\UrlFont}{\ttfamily\small}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

% Content lightly modified from original work by Jesse Dodge and Noah Smith


\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{CS598 DL4HC Reproducibility Project Proposal}

\author{Michael Miller and Kurt Tuohy \\
  \texttt{\{msmille3, ktuohy\}@illinois.edu}
  \\[2em]
  Presentation link: n/a\url{} \\
  Code link: \url{https://github.com/mich1eal/cs598_dl4hc}} 

\begin{document}
\maketitle

% All sections are mandatory.
% Keep in mind that your page limit is 8, excluding references.
% For specific grading rubrics, please see the project instruction.

\section{Paper ID 41: Symptom Similarity Analysis}
\subsection{General Problem}
The first paper we propose reproducing is ``\usebibentry{zhang_2019}{title}'' by \citeauthor*{zhang_2019}.

The primary goal of this paper is to rate the similarity of pairs of sentences. The idea is to aid prediction of disease by automatically identifying similarities in descriptions of patient symptoms. However, the paper does not use healthcare-related text.

\subsection{Specific Novel Approach}
\citet{zhang_2019} preprocess each sentence by extracting its ``trunk'' -- the subject, predicate and object. The researchers found that these trunks help identify sentence similarity more reliably.

\subsection{Specific Hypotheses to Verify}
We propose reproducing experiment 1. This creates and tests a classifier using a dataset of human-labeled sentence similarities. Experiment 1 compares the authors' method to a baseline plus the methods in four related papers.

\subsection{Additional Ablations}
Possible Ablations:
\begin{itemize}
  \item Incorporate synonyms, antonyms, and other word relationships into the model to gauge how this affects ratings of sentence similarities. The paper doesn't use healthcare data, so normal English synonyms could be a proxy for gauging whether the model's performance on healthcare data would improve by incorporating medical ontologies. One potential source of synonyms is the \href{https://www.kaggle.com/datasets/duketemon/wordnet-synonyms}{WordNet synonyms dataset} on Kaggle.
  \item Add an attention mechanism to learn which portions of sentences contribute most to similarity scores.
  \item Reduce the size of the training set to learn how sensitive the outcome is to the training corpus size.
\end{itemize}

\subsection{Data Access}
The training and testing datasets are public: the \href{https://www.microsoft.com/en-us/download/details.aspx?id=52398}{Microsoft Research Paraphrase Corpus} (MSRP) and the SemEval \href{https://github.com/brmson/dataset-sts/tree/master/data/sts/semeval-sts}{Semantic Text Similarity} (STS) datasets.

\subsection{Computational Feasibility}
The training dataset is small: 4,076 pairs of sentences. The authors use the \href{https://nlp.stanford.edu/software/lex-parser.shtml}{Stanford Parser} to extract sentence trunks, and this parser is publicly available. Finally, the authors' model uses only a small CNN, with one convolution layer and one pooling layer. We do not anticipate challenges in terms of computation power. 

\subsection{Code Reuse}
To date, the authors have not responded to our request for code. We would implement these methods ourselves. 

We can use the Python module \href{https://spacy.io/}{Spacy} or the \href{https://www.nltk.org/}{Natural Language Tool Kit} as tools for word tokenization and dependency parsing. 

\section{Paper ID 68: MuLan: Multilevel Language-Based Representation Learning}
\subsection{General Problem}
Our second paper is ``\usebibentry{sohn_2020}{title}'' by \citeauthor*{sohn_2020}. This paper seeks to:
\begin{itemize}
  \item Summarize EHRs as a chronology of medical events
  \item Interpret and visualize disease progression
  \item Provide early detection of dangerous conditions such as septic shock
\end{itemize}

\subsection{Specific Approach}
Unlike with Med2Vec, the authors model EHR hierarchies by using supervised learning for the final stage. This learns the relationship between patient visits and medical events in terms of a target condition such as septic shock.

Before the final stage, the authors model medical events as a sequence of states and state changes, such as blood pressure changing from low to high. They then use these state representations to identify relationships between events. This makes a difference for identifying septic shock, which has no single biological marker.

\subsection{Specific Hypotheses to Verify}
We would verify the prediction of septic shock with a 40-hour hold-off window. We would compare four variations of MuLan with two baseline models: one based on Med2Vec and one based on (relatively) raw EHR features.

\subsection{Additional Ablations}
Possible Ablations:
\begin{itemize}
  \item Before training the models, we would remove medical events that may represent target leakage, such as administration of vasopressors.
  \item We could vary the size of the training dataset to learn the model's sensitivity to the amount of data available.
\end{itemize}

\subsection{Data Access}
This paper uses data from the Christiana Care Health System (CCHS). This data is not publicly available. The authors of this paper were contacted to determine if the data can be retrieved. At the time of writing, no response has been received from the authors.

We'd substitute MIMIC-III data for the original dataset. We'd attempt to select a study population using the same criteria as the researchers.

The authors used experts to label the original dataset. We'd attempt to label the presence of septic shock using the criteria listed in the paper.

\subsection{Computational Feasibility}

From the study population,
we randomly sampled 10,000 visits with 927,131 events

As a result, the final dataset contains 5,928
visits with 795,314 events

CNN and LSTM

\subsection{Code Reuse}
Without an author response, we would write our own code.

\section{Paper ID 117: NLP for Cognitive Therapy}
\subsection{General Problem}
Our final paper is ``\usebibentry{burger_2021}{title}'' by \citeauthor*{burger_2021}. This paper seeks to classify a human subject's \emph{maladaptive schema} based on their unstructured text input. 

\subsection{Specific Novel Approach}
The task attempted by \citet{burger_2021} is particularly challenging. Inputs are unstructured natural language utterances from a variety of authors. In addition to the usual challenges of natural language, the classification target (psychological mental state) is highly subjective and likely varies person to person. This task is challenging for humans, requiring trained professionals who often do not reach consensus. Due to these obstacles, this task will likely be more challenging than typical natural language processing applications. 

\subsection{Specific Hypotheses to Verify}
We will attempt to verify the paper's hypothesis H1. This hypothesis asserts that mental health schema can be predicted given an unstructured utterance. 

\subsection{Additional Ablations}
Possible Ablations:
\begin{itemize}
  \item easy one - use a state of the art model like BERT, see if we can beat their scores 
  \item I wonder if there's anything else we can do with the hierarchical nature of their data. Maybe when you compile more than one utterance together you get better results?
\end{itemize}

\subsection{Data Access}
All data used in this paper is publicly available on the \href{https://data.4tu.nl/info/en/about-4turesearchdata/organisation}{4TU.ResearchData} repository. It has been successfully retrieved. 

\subsection{Computational Feasibility}
This study relies on a relatively small dataset (5747 utterances). The models used are not especially complicated. No computational power challenges are anticipated. 

\subsection{Code Reuse}
The code from this study is available on \href{https://data.4tu.nl/info/en/about-4turesearchdata/organisation}{4TU.ResearchData}. The code will be reviewed, however new code will be written for this project. Publicly available machine learning modules will be used when practical. 
\bibliographystyle{acl_natbib}
\bibliography{acl2021}

%\appendix



\end{document}
